{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pseudo-crab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sparks-baird/optimization-benchmark/blob/main/notebooks/pseudo_crab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QYspMfOYvo4B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d87b5995-4bef-4f83-b663-743f815ecf8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xtal2png\n",
            "  Downloading xtal2png-0.9.4-py3-none-any.whl (34 kB)\n",
            "Collecting crabnet\n",
            "  Downloading crabnet-2.0.7-py3-none-any.whl (35.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 35.2 MB 38 kB/s \n",
            "\u001b[?25hCollecting matbench\n",
            "  Downloading matbench-0.6-py3-none-any.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 41.1 MB/s \n",
            "\u001b[?25hCollecting ax-platform\n",
            "  Downloading ax_platform-0.2.5.1-py3-none-any.whl (993 kB)\n",
            "\u001b[K     |████████████████████████████████| 993 kB 50.5 MB/s \n",
            "\u001b[?25hCollecting xtal2png\n",
            "  Downloading xtal2png-0.9.3-py3-none-any.whl (34 kB)\n",
            "  Downloading xtal2png-0.9.2-py3-none-any.whl (34 kB)\n",
            "  Downloading xtal2png-0.9.1-py3-none-any.whl (34 kB)\n",
            "  Downloading xtal2png-0.9.0-py3-none-any.whl (34 kB)\n",
            "  Downloading xtal2png-0.8.0-py3-none-any.whl (30 kB)\n",
            "  Downloading xtal2png-0.7.1-py3-none-any.whl (30 kB)\n",
            "  Downloading xtal2png-0.7.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xtal2png) (1.21.6)\n",
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 79.9 MB 98 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from xtal2png) (7.1.2)\n",
            "Collecting pymatgen\n",
            "  Downloading pymatgen-2022.0.17.tar.gz (40.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 40.6 MB 1.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from xtal2png) (5.5.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from xtal2png) (4.12.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from crabnet) (0.11.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from crabnet) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from crabnet) (1.0.2)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from crabnet) (1.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from crabnet) (1.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from crabnet) (4.64.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from crabnet) (5.4.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from crabnet) (1.3.5)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.0.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.2 MB 1.5 MB/s \n",
            "\u001b[?25hCollecting matminer==0.7.4\n",
            "  Downloading matminer-0.7.4-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 51.1 MB/s \n",
            "\u001b[?25hCollecting monty==2022.4.26\n",
            "  Downloading monty-2022.4.26-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting requests>=2.26.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting future>=0.18.2\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 8.5 MB/s \n",
            "\u001b[?25hCollecting six>=1.16.0\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting sympy>=1.8\n",
            "  Downloading sympy-1.10.1-py3-none-any.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 44.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pymongo>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from matminer==0.7.4->matbench) (4.2.0)\n",
            "Requirement already satisfied: jsonschema>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from matminer==0.7.4->matbench) (4.3.3)\n",
            "Collecting pint>=0.17\n",
            "  Downloading Pint-0.18-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 39.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->crabnet) (3.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->matminer==0.7.4->matbench) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->matminer==0.7.4->matbench) (22.1.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->matminer==0.7.4->matbench) (5.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->matminer==0.7.4->matbench) (4.1.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.2.0->matminer==0.7.4->matbench) (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->crabnet) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->crabnet) (2022.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pint>=0.17->matminer==0.7.4->matbench) (21.3)\n",
            "Collecting ruamel.yaml>=0.15.6\n",
            "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 59.9 MB/s \n",
            "\u001b[?25hCollecting spglib>=1.9.9.44\n",
            "  Downloading spglib-1.16.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 53.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: palettable>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from pymatgen->xtal2png) (3.3.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from pymatgen->xtal2png) (2.6.3)\n",
            "Collecting uncertainties>=3.1.4\n",
            "  Downloading uncertainties-3.1.7-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from pymatgen->xtal2png) (0.8.10)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->crabnet) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->crabnet) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->crabnet) (1.4.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->xtal2png) (8.0.1)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26.0->matminer==0.7.4->matbench) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26.0->matminer==0.7.4->matbench) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26.0->matminer==0.7.4->matbench) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26.0->matminer==0.7.4->matbench) (2.10)\n",
            "Collecting ruamel.yaml.clib>=0.2.6\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
            "\u001b[K     |████████████████████████████████| 546 kB 70.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy>=1.8->matminer==0.7.4->matbench) (1.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from ax-platform) (2.11.3)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.7/dist-packages (from ax-platform) (2.7.1)\n",
            "Collecting botorch==0.6.4\n",
            "  Downloading botorch-0.6.4-py3-none-any.whl (363 kB)\n",
            "\u001b[K     |████████████████████████████████| 363 kB 57.5 MB/s \n",
            "\u001b[?25hCollecting multipledispatch\n",
            "  Downloading multipledispatch-0.6.0-py3-none-any.whl (11 kB)\n",
            "Collecting pyro-ppl==1.8.0\n",
            "  Downloading pyro_ppl-1.8.0-py3-none-any.whl (713 kB)\n",
            "\u001b[K     |████████████████████████████████| 713 kB 51.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.7/dist-packages (from botorch==0.6.4->ax-platform) (1.12.0+cu113)\n",
            "Collecting gpytorch>=1.6\n",
            "  Downloading gpytorch-1.8.0-py2.py3-none-any.whl (360 kB)\n",
            "\u001b[K     |████████████████████████████████| 360 kB 50.4 MB/s \n",
            "\u001b[?25hCollecting pyro-api>=0.1.1\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.8.0->botorch==0.6.4->ax-platform) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->ax-platform) (2.0.1)\n",
            "Building wheels for collected packages: future, pymatgen\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=c59d9a263e649d05270219f711f7dac366498d21ded71bd4bf43314cd871d690\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for pymatgen (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymatgen: filename=pymatgen-2022.0.17-cp37-cp37m-linux_x86_64.whl size=41841023 sha256=fdf51d04d84e870d5e32f03fe831ff230efaac3701555030781a310646677639\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/f6/22/58a9be23c5f1b452770e02ff42047175eaf0f9c2f15219fc76\n",
            "Successfully built future pymatgen\n",
            "Installing collected packages: six, ruamel.yaml.clib, future, uncertainties, sympy, spglib, scikit-learn, ruamel.yaml, requests, pyro-api, monty, pyro-ppl, pymatgen, pint, multipledispatch, gpytorch, matminer, kaleido, colorama, botorch, xtal2png, matbench, crabnet, ax-platform\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.7.1\n",
            "    Uninstalling sympy-1.7.1:\n",
            "      Successfully uninstalled sympy-1.7.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed ax-platform-0.2.5.1 botorch-0.6.4 colorama-0.4.5 crabnet-2.0.7 future-0.18.2 gpytorch-1.8.0 kaleido-0.2.1 matbench-0.6 matminer-0.7.4 monty-2022.4.26 multipledispatch-0.6.0 pint-0.18 pymatgen-2022.0.17 pyro-api-0.1.2 pyro-ppl-1.8.0 requests-2.28.1 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.6 scikit-learn-1.0.1 six-1.16.0 spglib-1.16.5 sympy-1.10.1 uncertainties-3.1.7 xtal2png-0.7.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "%pip install xtal2png crabnet matbench ax-platform"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xtal2png.utils.data import element_wise_scaler, element_wise_unscaler"
      ],
      "metadata": {
        "id": "dWYBbm1mvqSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$N$ as in number of attention layers (see [CrabNet hyperparameter manuscript](https://doi.org/10.1016/j.commatsci.2022.111505), Table 1)."
      ],
      "metadata": {
        "id": "HYfPY7JmxNLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "N_pseudo = [0.1, 0.125, 0.01, 0.0, 0.95]\n",
        "N_pseudo_range = [0, 1.0]\n",
        "N_range = [1, 10]\n",
        "N_actual = element_wise_scaler(N_pseudo, feature_range=N_range, data_range=N_pseudo_range)\n",
        "N_actual = np.int64(np.round(N_actual))\n",
        "print('N_actual:',N_actual)\n",
        "\n",
        "d_model_pseudo = np.arange(0, 1, 0.2)\n",
        "d_model_pseudo_range = [0, 1.0]\n",
        "d_model_range = [100, 1024]\n",
        "d_model_actual = element_wise_scaler(d_model_pseudo, feature_range=d_model_range, data_range=d_model_pseudo_range)\n",
        "d_model_actual = np.int64(np.round(d_model_actual))\n",
        "print('d_model_actual:',d_model_actual)\n",
        "\n",
        "dim_feedforward_pseudo = np.arange(0, 1, 0.2)\n",
        "dim_feedforward_pseudo_range = [0, 1.0]\n",
        "dim_feedforward_range = [1024, 4096]\n",
        "dim_feedforward_actual = element_wise_scaler(dim_feedforward_pseudo, feature_range=dim_feedforward_range, data_range=dim_feedforward_pseudo_range)\n",
        "dim_feedforward_actual = np.int64(np.round(dim_feedforward_actual))\n",
        "print('dim_feedforward_actual:',dim_feedforward_actual)\n",
        "\n",
        "eps_pseudo = np.arange(0, 1, 0.2)\n",
        "eps_pseudo_range = [0, 1.0]\n",
        "eps_range = [1e-7, 1e-4]\n",
        "eps_actual = element_wise_scaler(eps_pseudo,feature_range=eps_range, data_range=eps_pseudo_range)\n",
        "eps_actual = np.float64(np.around(eps_actual, decimals=7, out=None))\n",
        "print('eps_actual:',eps_actual)\n",
        "\n",
        "fudge_pseudo = np.arange(0, 1, 0.2)\n",
        "fudge_pseudo_range = [0, 1.0]\n",
        "fudge_range = [0, 0.1]\n",
        "fudge_actual = element_wise_scaler(fudge_pseudo, feature_range=fudge_range, data_range=fudge_pseudo_range)\n",
        "print('fudge_actual:',fudge_actual)\n",
        "\n",
        "heads_pseudo = np.arange(0, 1, 0.2)\n",
        "heads_pseudo_range = [0, 1.0]\n",
        "heads_range = [1, 10]\n",
        "heads_actual = element_wise_scaler(heads_pseudo, feature_range=heads_range, data_range=heads_pseudo_range)\n",
        "heads_actual = np.int64(np.round(heads_actual))\n",
        "print('heads:',heads_actual)\n",
        "\n",
        "k_pseudo = np.arange(0, 1, 0.2)\n",
        "k_pseudo_range = [0, 1.0]\n",
        "k_range = [2, 10]\n",
        "k_actual = element_wise_scaler(k_pseudo, feature_range=k_range, data_range=k_pseudo_range)\n",
        "k_actual = np.int64(np.round(k_actual))\n",
        "print('k_actual:',k_actual)\n",
        "\n",
        "lr_pseudo = np.arange(0, 1, 0.2)\n",
        "lr_pseudo_range = [0, 1.0]\n",
        "lr_range = [1e-4, 6e-3]\n",
        "lr_actual = element_wise_scaler(lr_pseudo, feature_range=lr_range, data_range=lr_pseudo_range)\n",
        "lr_actual = np.float64(np.around(lr_actual, decimals=4, out=None)) # to check the floating point round off\n",
        "print('lr_actual:',lr_actual)\n",
        "\n",
        "pe_resolution_pseudo = np.arange(0, 1, 0.2)\n",
        "pe_resolution_pseudo_range = [0, 1.0]\n",
        "pe_resolution_range = [2500, 10000]\n",
        "pe_resolution_actual = element_wise_scaler(pe_resolution_pseudo, feature_range=pe_resolution_range, data_range=pe_resolution_pseudo_range)\n",
        "pe_resolution_actual = np.int64(np.round(pe_resolution_actual))\n",
        "print('pe_resolution_actual:',pe_resolution_actual)\n",
        "\n",
        "ple_resolution_pseudo = np.arange(0, 1, 0.2)\n",
        "ple_resolution_pseudo_range = [0, 1.0]\n",
        "ple_resolution_range = [2500, 10000]\n",
        "ple_resolution_actual = element_wise_scaler(ple_resolution_pseudo, feature_range=ple_resolution_range, data_range=ple_resolution_pseudo_range)\n",
        "ple_resolution_actual = np.int64(np.round(ple_resolution_actual))\n",
        "print('ple_resolution_actual:',ple_resolution_actual)\n",
        "\n",
        "batch_size_pseudo = np.arange(0, 1, 0.2)\n",
        "batch_size_pseudo_range = [0, 1.0]\n",
        "batch_size_range = [32, 256] ### (continuous or discrete like 32,64,128,256)\n",
        "batch_size_actual = element_wise_scaler(batch_size_pseudo, feature_range=batch_size_range,data_range=batch_size_pseudo_range)\n",
        "batch_size_actual = np.int64(np.round(batch_size_actual))\n",
        "print('batch_size_actual:',batch_size_actual)\n",
        "\n",
        "out_hidden4_pseudo = np.arange(0, 1, 0.2)\n",
        "out_hidden4_pseudo_range = [0, 1.0]\n",
        "out_hidden4_range = [32, 512]\n",
        "out_hidden_actual = element_wise_scaler(out_hidden4_pseudo, feature_range=out_hidden4_range, data_range=out_hidden4_pseudo_range)\n",
        "out_hidden_actual = np.int64(np.round(out_hidden_actual))\n",
        "print('out_hidden_actual:',out_hidden_actual)\n",
        "\n",
        "betas1_pseudo = np.arange(0, 1, 0.2)\n",
        "betas1_pseudo_range = [0, 1.0]\n",
        "betas1_range = [0.5, 0.9999]\n",
        "betas1_actual = element_wise_scaler(betas1_pseudo,feature_range=betas1_range,data_range=betas1_pseudo_range)\n",
        "betas1_actual = np.float64(np.around(betas1_actual, decimals=4, out=None)) # to check the floating point round off\n",
        "print('betas1_actual:',betas1_actual)\n",
        "\n",
        "betas2_pseudo = np.arange(0, 1, 0.2)\n",
        "betas2_pseudo_range = [0, 1.0]\n",
        "betas2_range = [0.5, 0.9999]\n",
        "betas2_actual = element_wise_scaler(betas2_pseudo,feature_range=betas2_range,data_range=betas2_pseudo_range)\n",
        "betas2_actual = np.float64(np.around(betas2_actual, decimals=4, out=None)) # to check the floating point round off\n",
        "print('betas2_actual:',betas2_actual)\n",
        "\n",
        "\n",
        "epochs_step_pseudo = [0.5, 0.001, 0.25, 0.63, 0.65]\n",
        "epochs_step_pseudo_range = [0, 1.0]\n",
        "epochs_step_range = [5, 20]\n",
        "epochs_step_actual = element_wise_scaler(epochs_step_pseudo, feature_range=epochs_step_range, data_range=epochs_step_pseudo_range)\n",
        "epochs_step_actual = np.int64(np.round(epochs_step_actual))\n",
        "print('epochs_step_actual:',epochs_step_actual)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpmvJo2EwNgi",
        "outputId": "6f9663c1-caf6-4684-cef2-8f4d6ef18fe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N_actual: [ 2  2  1  1 10]\n",
            "d_model_actual: [100 285 470 654 839]\n",
            "dim_feedforward_actual: [1024 1638 2253 2867 3482]\n",
            "eps_actual: [1.00e-07 2.01e-05 4.01e-05 6.00e-05 8.00e-05]\n",
            "fudge_actual: [0.   0.02 0.04 0.06 0.08]\n",
            "heads: [1 3 5 6 8]\n",
            "k_actual: [2 4 5 7 8]\n",
            "lr_actual: [0.0001 0.0013 0.0025 0.0036 0.0048]\n",
            "pe_resolution_actual: [2500 4000 5500 7000 8500]\n",
            "ple_resolution_actual: [2500 4000 5500 7000 8500]\n",
            "batch_size_actual: [ 32  77 122 166 211]\n",
            "out_hidden_actual: [ 32 128 224 320 416]\n",
            "betas1_actual: [0.5    0.6    0.7    0.7999 0.8999]\n",
            "betas2_actual: [0.5    0.6    0.7    0.7999 0.8999]\n",
            "epochs_step_actual: [12  5  9 14 15]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "def correct_parameterization(parameterization: dict, verbose=False):\n",
        "    # take dictionary of tunable hyperparameters and output hyperparameter combinations compatible with CrabNet\n",
        "    if verbose:\n",
        "        pprint.pprint(parameterization)\n",
        "\n",
        "    parameterization[\"out_hidden\"] = [\n",
        "        parameterization.get(\"out_hidden4\") * 8,\n",
        "        parameterization.get(\"out_hidden4\") * 4,\n",
        "        parameterization.get(\"out_hidden4\") * 2,\n",
        "        parameterization.get(\"out_hidden4\"),\n",
        "    ]\n",
        "    parameterization.pop(\"out_hidden4\")\n",
        "\n",
        "    parameterization[\"betas\"] = (\n",
        "        parameterization.get(\"betas1\"),\n",
        "        parameterization.get(\"betas2\"),\n",
        "    )\n",
        "    parameterization.pop(\"betas1\")\n",
        "    parameterization.pop(\"betas2\")\n",
        "\n",
        "    d_model = parameterization[\"d_model\"]\n",
        "\n",
        "    # make heads even (unless it's 1) (because d_model must be even)\n",
        "    heads = parameterization[\"heads\"]\n",
        "    if np.mod(heads, 2) != 0:\n",
        "        heads = heads + 1\n",
        "    parameterization[\"heads\"] = heads\n",
        "\n",
        "    # NOTE: d_model must be divisible by heads\n",
        "    d_model = parameterization[\"heads\"] * round(d_model / parameterization[\"heads\"])\n",
        "\n",
        "    parameterization[\"d_model\"] = d_model\n",
        "\n",
        "    parameterization[\"pos_scaler_log\"] = (\n",
        "        1 - parameterization[\"emb_scaler\"] - parameterization[\"pos_scaler\"]\n",
        "    )\n",
        "\n",
        "    parameterization[\"epochs\"] = parameterization[\"epochs_step\"] * 4\n",
        "\n",
        "    return parameterization"
      ],
      "metadata": {
        "id": "JbKghPdfXzj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy = True #@param {type:\"boolean\"}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LK8eHgSwpaN",
        "outputId": "c689ea5e-cd47-4f59-8a1a-462be93c2a10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model architecture: out_dims, d_model, N, heads\n",
            "3, 512, 2, 4\n",
            "Running on compute device: cpu\n",
            "2022-07-27 21:55:14 INFO     Initialized benchmark 'matbench_v0.1' with 1 tasks: \n",
            "['matbench_expt_gap']\n",
            "2022-07-27 21:55:14 INFO     Loading dataset 'matbench_expt_gap'...\n",
            "2022-07-27 21:55:14 INFO     Dataset 'matbench_expt_gap loaded.\n",
            "Model size: 8834822 parameters\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating EDM: 100%|██████████| 8/8 [00:00<00:00, 26525.24formulae/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data with up to 4 elements in the formula\n",
            "training with batchsize 128 (2**7.000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating EDM: 100%|██████████| 2/2 [00:00<00:00, 10280.16formulae/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data with up to 4 elements in the formula\n",
            "stepping every 5 training passes, cycling lr every 5 epochs\n",
            "checkin at 10 epochs to match lr scheduler\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/20 --- train mae: 0.949 val mae: 1.03\n",
            "Epoch: 9/20 --- train mae: 0.502 val mae: 1.12\n",
            "Epoch 19 failed to improve.\n",
            "Discarded: 1/3 weight updates\n",
            "Epoch: 19/20 --- train mae: 0.346 val mae: 1.29\n",
            "Saving network (UnnamedModel) to models/trained_models/UnnamedModel.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating EDM: 100%|██████████| 921/921 [00:00<00:00, 116723.19formulae/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data with up to 4 elements in the formula\n",
            "2022-07-27 21:55:22 INFO     Recorded fold matbench_expt_gap-0 successfully.\n",
            "Model size: 8834822 parameters\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating EDM: 100%|██████████| 8/8 [00:00<00:00, 32640.50formulae/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data with up to 4 elements in the formula\n",
            "training with batchsize 128 (2**7.000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating EDM: 100%|██████████| 2/2 [00:00<00:00, 9049.20formulae/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data with up to 4 elements in the formula\n",
            "stepping every 5 training passes, cycling lr every 5 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/20 --- train mae: 0.837 val mae: 0.622\n",
            "Epoch: 9/20 --- train mae: 0.555 val mae: 1.12\n",
            "Epoch 19 failed to improve.\n",
            "Discarded: 1/3 weight updates\n",
            "Epoch: 19/20 --- train mae: 0.534 val mae: 1.67\n",
            "Saving network (UnnamedModel) to models/trained_models/UnnamedModel.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating EDM: 100%|██████████| 921/921 [00:00<00:00, 94193.12formulae/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data with up to 4 elements in the formula\n",
            "2022-07-27 21:55:28 INFO     Recorded fold matbench_expt_gap-1 successfully.\n",
            "Model size: 8834822 parameters\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating EDM: 100%|██████████| 8/8 [00:00<00:00, 30727.50formulae/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data with up to 4 elements in the formula\n",
            "training with batchsize 128 (2**7.000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating EDM: 100%|██████████| 2/2 [00:00<00:00, 8648.05formulae/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data with up to 4 elements in the formula\n",
            "stepping every 5 training passes, cycling lr every 5 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/20 --- train mae: 0.76 val mae: 0.485\n",
            "Epoch: 9/20 --- train mae: 0.595 val mae: 0.303\n",
            "Epoch: 19/20 --- train mae: 0.499 val mae: 0.107\n",
            "Saving network (UnnamedModel) to models/trained_models/UnnamedModel.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating EDM: 100%|██████████| 921/921 [00:00<00:00, 83838.74formulae/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data with up to 4 elements in the formula\n",
            "2022-07-27 21:55:34 INFO     Recorded fold matbench_expt_gap-2 successfully.\n",
            "Model size: 8834822 parameters\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating EDM: 100%|██████████| 8/8 [00:00<00:00, 34169.48formulae/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data with up to 4 elements in the formula\n",
            "training with batchsize 128 (2**7.000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating EDM: 100%|██████████| 2/2 [00:00<00:00, 8224.13formulae/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data with up to 4 elements in the formula\n",
            "stepping every 5 training passes, cycling lr every 5 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/20 --- train mae: 0.385 val mae: 1.29\n",
            "Epoch: 9/20 --- train mae: 0.329 val mae: 1.12\n",
            "Epoch: 19/20 --- train mae: 0.231 val mae: 0.928\n",
            "Saving network (UnnamedModel) to models/trained_models/UnnamedModel.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating EDM: 100%|██████████| 921/921 [00:00<00:00, 67416.30formulae/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data with up to 4 elements in the formula\n",
            "2022-07-27 21:55:40 INFO     Recorded fold matbench_expt_gap-3 successfully.\n",
            "Model size: 8834822 parameters\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating EDM: 100%|██████████| 8/8 [00:00<00:00, 13640.01formulae/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data with up to 4 elements in the formula\n",
            "training with batchsize 128 (2**7.000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating EDM: 100%|██████████| 2/2 [00:00<00:00, 8858.09formulae/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data with up to 4 elements in the formula\n",
            "stepping every 5 training passes, cycling lr every 5 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/20 --- train mae: 0.89 val mae: 0.68\n",
            "Epoch: 9/20 --- train mae: 0.381 val mae: 1.4\n",
            "Epoch 19 failed to improve.\n",
            "Discarded: 1/3 weight updates\n",
            "Epoch: 19/20 --- train mae: 0.232 val mae: 1.45\n",
            "Saving network (UnnamedModel) to models/trained_models/UnnamedModel.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating EDM: 100%|██████████| 920/920 [00:00<00:00, 94514.90formulae/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data with up to 4 elements in the formula\n",
            "2022-07-27 21:55:46 INFO     Recorded fold matbench_expt_gap-4 successfully.\n",
            "2022-07-27 21:55:46 INFO     Successfully wrote MatbenchBenchmark to file 'results.json.gz'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from crabnet.crabnet_ import CrabNet\n",
        "from matbench.bench import MatbenchBenchmark\n",
        "\n",
        "cb = CrabNet(N=N_actual[0], epochs_step=5, epochs=20, losscurve=False, learningcurve=False)\n",
        "mb = MatbenchBenchmark(autoload=False, subset = [\"matbench_expt_gap\"])\n",
        "\n",
        "for task in mb.tasks:\n",
        "    task.load()\n",
        "    for fold in task.folds:\n",
        "\n",
        "        # Inputs are either chemical compositions as strings\n",
        "        # or crystal structures as pymatgen.Structure objects.\n",
        "        # Outputs are either floats (regression tasks) or bools (classification tasks)\n",
        "        train_inputs, train_outputs = task.get_train_and_val_data(fold)\n",
        "\n",
        "        # prep input for CrabNet\n",
        "        train_df = pd.concat((train_inputs, train_outputs), axis=1, keys=[\"formula\", \"target\"])\n",
        "\n",
        "        if dummy:\n",
        "          train_df = train_df.head(10)\n",
        "\n",
        "        # train and validate your model\n",
        "        cb.fit(train_df = train_df)\n",
        "\n",
        "        # Get testing data\n",
        "        test_inputs, test_outputs = task.get_test_data(fold, include_target=True)\n",
        "        test_df = pd.concat((test_inputs, test_outputs), axis=1, keys=[\"formula\", \"target\"])\n",
        "\n",
        "        # Predict on the testing data\n",
        "        # Your output should be a pandas series, numpy array, or python iterable\n",
        "        # where the array elements are floats or bools\n",
        "        predictions = cb.predict(test_df = test_df)\n",
        "\n",
        "        # Record your data!\n",
        "        task.record(fold, predictions)\n",
        "\n",
        "# Save your results\n",
        "mb.to_file(\"results.json.gz\")"
      ],
      "metadata": {
        "id": "k0YXjGUJPvAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task.scores"
      ],
      "metadata": {
        "id": "mK3ZRfWfFdTq",
        "outputId": "10479d5e-d8fa-41a6-b752-cdc93c7c642a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_ipython_canary_method_should_not_exist_': {},\n",
              " 'mae': {'max': 1.2193523994486186,\n",
              "  'mean': 0.9998868909545781,\n",
              "  'min': 0.9014170849155008,\n",
              "  'std': 0.11202472905111112},\n",
              " 'mape': {'max': 0.9394993956372839,\n",
              "  'mean': 0.819026979862538,\n",
              "  'min': 0.7049084112330609,\n",
              "  'std': 0.08287124405517027},\n",
              " 'max_error': {'max': 11.506120574474334,\n",
              "  'mean': 9.406438809394837,\n",
              "  'min': 6.800493836402893,\n",
              "  'std': 1.7578161814429192},\n",
              " 'rmse': {'max': 1.5885576047526244,\n",
              "  'mean': 1.4456771983062426,\n",
              "  'min': 1.2912141514625954,\n",
              "  'std': 0.10554199347287692}}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task.scores[\"mae\"][\"mean\"]"
      ],
      "metadata": {
        "id": "LIqjz50qznz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a0a7e5-ba8e-413b-8844-e7f3867d079a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0495031936344357"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PseudoCrab\n",
        "\n",
        "Main public-facing class"
      ],
      "metadata": {
        "id": "Q-C3_xGV1DIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "SUPPORTED_OBJECTIVES = [\"mae\", \"rmse\", \"runtime\", \"model_size\"]\n",
        "FLOAT_LIMIT = 20\n",
        "CATEGORICAL_LIMIT = 3\n",
        "\n",
        "class PseudoCrab(object):\n",
        "  def __init__(self,\n",
        "               objectives:List[str]=[\"mae\"],\n",
        "               iteration_budget: int=100,\n",
        "               n_float_params: int=3,\n",
        "               n_categorical_params: int=0,\n",
        "               constraint_fn: Optional[callable]=None):\n",
        "    for obj in objectives:\n",
        "      assert obj in SUPPORTED_OBJECTIVES, f\"Unsupported objective: {obj}. Must be in {SUPPORTED_OBJECTIVES}\"\n",
        "\n",
        "    self.objectives = objectives\n",
        "    self.iteration_budget = iteration_budget\n",
        "\n",
        "    # TODO: separate between float and int parameters\n",
        "    if n_float_params > FLOAT_LIMIT:\n",
        "      raise ValueError(f\"{n_float_params} float parameters requested. No more than {FLOAT_LIMIT} allowed.\")\n",
        "    self.n_float_params = n_float_params\n",
        "\n",
        "    if n_categorical_params > CATEGORICAL_LIMIT:\n",
        "      raise ValueError(f\"{n_categorical_params} categorical parameters requested. No more than {CATEGORICAL_LIMIT} allowed.\")\n",
        "    self.n_categorical_params = n_categorical_params\n",
        "\n",
        "    self.constraint_fn = constraint_fn if constraint_fn is not None else lambda x: True\n",
        "\n",
        "    self.n_objectives = len(objectives)\n",
        "    self.expected_float_keys = [f\"x{i}\" for i in range(1, self.n_float_params + 1)]\n",
        "    self.expected_categorical_keys = [f\"c{i}\" for i in range(1, self.n_categorical_params + 1)]\n",
        "    self.expected_keys = self.expected_float_keys + self.expected_categorical_keys\n",
        "\n",
        "    self.__num_evaluations = 0\n",
        "\n",
        "  @property\n",
        "  def num_evaluations(self):\n",
        "    return self.__num_evaluations\n",
        "\n",
        "  def evaluate(self, parameters):\n",
        "    self.__num_evaluations = self.num_evaluations + 1\n",
        "\n",
        "    if self.num_evaluations > self.iteration_budget:\n",
        "      raise ValueError(\"maximum number of evaluations has been reached\")\n",
        "\n",
        "    keys = list(parameters.keys())\n",
        "\n",
        "    err_msg = \"\"\n",
        "    missing_keys = np.setdiff1d(keys, self.expected_keys)\n",
        "    if missing_keys:\n",
        "      err_msg = err_msg + f\"missing keys in parameters: {missing_keys}. \"\n",
        "\n",
        "    extra_keys = np.setdiff1d(self.expected_keys, keys)\n",
        "    if extra_keys:\n",
        "      err_msg = err_msg + f\"extra keys in parameters: {extra_keys}. \"\n",
        "\n",
        "    if err_msg != \"\":\n",
        "      raise KeyError(err_msg)\n",
        "  \n",
        "    # TODO: compute and return CrabNet objective(s) as dictionary\n",
        "    crabnet_mae = 0.123 # eV (dummy value)\n",
        "    crabnet_rmse = 0.234 # eV (dummy value)\n",
        "    runtime = 125 # seconds (dummy value)\n",
        "    model_size = 123456 # parameters (dummy value)\n",
        "\n",
        "    outputs = {\"mae\": crabnet_mae, \"rmse\": crabnet_rmse, \"runtime\": runtime, \"model_size\": model_size}\n",
        "\n",
        "    return {k: outputs[k] for k in outputs.keys() if k in self.objectives}\n",
        "  "
      ],
      "metadata": {
        "id": "LRPlEebLf1-a"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Usage (/Test)"
      ],
      "metadata": {
        "id": "_l7WT6YevtjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_dummy_fn = False #@param {type:\"boolean\"}\n",
        "\n",
        "if use_dummy_fn:\n",
        "  objective_names = [\"mae\", \"rmse\"]\n",
        "  iteration_budget = 3\n",
        "  n_float_params = 5\n",
        "  n_categorical_params = 2\n",
        "else:\n",
        "  objective_names = [\"mae\", \"rmse\"]\n",
        "  iteration_budget = 3 #@param {type:\"integer\"}\n",
        "  n_float_params = 5 #@param {type: \"integer\"}  \n",
        "  n_categorical_params = 2 #@param {type: \"integer\"}\n",
        "\n",
        "n_objectives = len(objective_names)\n",
        "\n",
        "def example_constraint_fn(parameters):\n",
        "  \"\"\"Return True if x1 + x2 <= 1.0, else False.\"\"\"\n",
        "  if parameters[\"x1\"] + parameters[\"x2\"] <= 1.0:\n",
        "    return True\n",
        "  return False"
      ],
      "metadata": {
        "id": "5Tr92QAON6Mo"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implement an Ax search here for an example, and create a dummy function to run in place of PseudoCrab for demo purposes\n",
        "\"\"\"Adapted from https://ax.dev/docs/api.html and https://ax.dev/tutorials/multiobjective_optimization.html\"\"\"\n",
        "from ax.service.ax_client import AxClient\n",
        "from ax.service.utils.instantiation import ObjectiveProperties\n",
        "from botorch.test_functions.multi_objective import BraninCurrin  # for dummy fn\n",
        "import torch  # for dummy fn\n",
        "from ax.modelbridge.generation_strategy import GenerationStrategy, GenerationStep\n",
        "from ax.modelbridge.registry import Models\n",
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "\n",
        "# Load our sample 2-objective problem\n",
        "branin_currin = BraninCurrin(negate=True).to(\n",
        "    dtype=torch.double,\n",
        "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
        ")\n",
        "\n",
        "\n",
        "def dummy_evaluate(parameters):\n",
        "    evaluation = branin_currin(\n",
        "        torch.tensor([parameters.get(\"x1\"), parameters.get(\"x2\")])\n",
        "    )\n",
        "    parameters[\"x3\"]  # unused float parameter\n",
        "    parameters[\"x4\"]  # unused float parameter\n",
        "    parameters[\"x5\"]  # unused float parameter\n",
        "    parameters[\"c1\"]  # unused categorical parameter\n",
        "    parameters[\"c2\"]  # unused categorical parameter\n",
        "    branin_measured = evaluation[0].item()\n",
        "    currin_measured = evaluation[1].item()\n",
        "    return {\"objective_1\": branin_measured, \"objective_2\": currin_measured}\n",
        "\n",
        "\n",
        "if use_dummy_fn:\n",
        "    if n_objectives != 2 or n_float_params != 5 or n_categorical_params != 2:\n",
        "        raise ValueError(\n",
        "            \"dummy_evaluate is hardcoded for 2 objectives, 5 float parameters, and 2 categorical parameters\"\n",
        "        )\n",
        "    evaluation_function = dummy_evaluate\n",
        "else:\n",
        "    pc = PseudoCrab(\n",
        "        objectives=objective_names,\n",
        "        constraint_fn=example_constraint_fn,\n",
        "        iteration_budget=iteration_budget,\n",
        "        n_float_params=n_float_params,\n",
        "        n_categorical_params=n_categorical_params,\n",
        "        # complexity=2,\n",
        "    )\n",
        "    # REVIEW: encode some way of changing the complexity of the task (e.g. runtime cost, response surface smoothness)\n",
        "    # e.g. for iteration_cost, specify how many training datapoints are used internally\n",
        "\n",
        "    dummy_parameters = {\n",
        "        **{f\"x{i}\": 0.1 for i in range(1, 6)},\n",
        "        **{f\"c{i}\": \"option_1\" for i in range(1, 3)},\n",
        "    }\n",
        "    deepcopy(pc).evaluate(dummy_parameters)  # test that it runs with a simple case\n",
        "    evaluation_function = pc.evaluate\n",
        "composition_bounds = [0.0, 1.0]\n",
        "\n",
        "\n",
        "def make_options(num_options):\n",
        "    \"\"\"E.g. make_options(3) == [\"option_1\", \"option_2\", \"option_3\"]\"\"\"\n",
        "    return [f\"option_{i}\" for i in range(1, num_options + 1)]\n",
        "\n",
        "\n",
        "def make_objectives(num_objectives):\n",
        "    \"\"\"E.g. make_objectives(2) == [\"mae\": ObjectiveProperties(minimize=True), \"rmse\": ObjectiveProperties(minimize=True)}\"\"\"\n",
        "    return {name: ObjectiveProperties(minimize=True) for name in objective_names[:num_objectives]}\n",
        "\n",
        "\n",
        "objectives = make_objectives(n_objectives)\n",
        "\n",
        "if n_objectives == 1:\n",
        "    model = Models.GPEI\n",
        "else:\n",
        "    model = Models.MOO\n",
        "gs = GenerationStrategy(\n",
        "    steps=[\n",
        "        # 1. Initialization step (does not require pre-existing data and is well-suited for\n",
        "        # initial sampling of the search space)\n",
        "        GenerationStep(\n",
        "            model=Models.SOBOL,\n",
        "            num_trials=max(\n",
        "                2, 5 - iteration_budget\n",
        "            ),  # How many trials should be produced from this generation step\n",
        "        ),\n",
        "        # 2. Bayesian optimization step (requires data obtained from previous phase and learns\n",
        "        # from all data available at the time of each new candidate generation call)\n",
        "        GenerationStep(\n",
        "            model=model,\n",
        "            num_trials=-1,  # No limitation on how many trials should be produced from this step\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "ax_client = AxClient(generation_strategy=gs)\n",
        "ax_client.create_experiment(\n",
        "    name=\"pseudo_crab_experiment\",\n",
        "    parameters=[\n",
        "        {\n",
        "            \"name\": \"x1\",\n",
        "            \"type\": \"range\",\n",
        "            \"bounds\": composition_bounds,\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"x2\",\n",
        "            \"type\": \"range\",\n",
        "            \"bounds\": composition_bounds,\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"x3\",\n",
        "            \"type\": \"range\",\n",
        "            \"bounds\": composition_bounds,\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"x4\",\n",
        "            \"type\": \"range\",\n",
        "            \"bounds\": composition_bounds,\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"x5\",\n",
        "            \"type\": \"range\",\n",
        "            \"bounds\": composition_bounds,\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"c1\",\n",
        "            \"type\": \"choice\",\n",
        "            \"values\": make_options(\n",
        "                3\n",
        "            ),  # number of options should match corresponding CrabNet hyperparameter\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"c2\",\n",
        "            \"type\": \"choice\",\n",
        "            \"values\": make_options(\n",
        "                3\n",
        "            ),  # number of options should match corresponding CrabNet hyperparameter\n",
        "        },\n",
        "    ],\n",
        "    objectives=objectives,\n",
        ")\n",
        "\n",
        "for _ in range(iteration_budget):\n",
        "    parameters, trial_index = ax_client.get_next_trial()\n",
        "    ax_client.complete_trial(\n",
        "        trial_index=trial_index, raw_data=evaluation_function(parameters)\n",
        "    )\n",
        "\n",
        "if n_objectives == 1:\n",
        "    best_parameters, metrics = ax_client.get_best_parameters()\n",
        "    pareto_optimal_parameters = None\n",
        "else:\n",
        "    best_parameters = None\n",
        "    pareto_optimal_parameters = ax_client.get_pareto_optimal_parameters()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe63jHrPOwPo",
        "outputId": "78d07057-e690-468b-d164-af9bdc2f1b5f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "[INFO 08-03 04:09:56] ax.service.ax_client: Starting optimization with verbose logging. To disable logging, set the `verbose_logging` argument to `False`. Note that float values in the logs are rounded to 6 decimal points.\n",
            "[INFO 08-03 04:09:56] ax.service.utils.instantiation: Due to non-specification, we will use the heuristic for selecting objective thresholds.\n",
            "[INFO 08-03 04:09:56] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter x1. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
            "[INFO 08-03 04:09:56] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter x2. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
            "[INFO 08-03 04:09:56] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter x3. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
            "[INFO 08-03 04:09:56] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter x4. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
            "[INFO 08-03 04:09:56] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter x5. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
            "[INFO 08-03 04:09:56] ax.service.utils.instantiation: Inferred value type of ParameterType.STRING for parameter c1. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
            "/usr/local/lib/python3.7/dist-packages/ax/core/parameter.py:468: UserWarning: `is_ordered` is not specified for `ChoiceParameter` \"c1\". Defaulting to `False` for parameters of `ParameterType` STRING. To override this behavior (or avoid this warning), specify `is_ordered` during `ChoiceParameter` construction.\n",
            "  f'`{param_string}` is not specified for `ChoiceParameter` \"{self._name}\". '\n",
            "/usr/local/lib/python3.7/dist-packages/ax/core/parameter.py:468: UserWarning: `sort_values` is not specified for `ChoiceParameter` \"c1\". Defaulting to `False` for parameters of `ParameterType` STRING. To override this behavior (or avoid this warning), specify `sort_values` during `ChoiceParameter` construction.\n",
            "  f'`{param_string}` is not specified for `ChoiceParameter` \"{self._name}\". '\n",
            "[INFO 08-03 04:09:56] ax.service.utils.instantiation: Inferred value type of ParameterType.STRING for parameter c2. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
            "/usr/local/lib/python3.7/dist-packages/ax/core/parameter.py:468: UserWarning: `is_ordered` is not specified for `ChoiceParameter` \"c2\". Defaulting to `False` for parameters of `ParameterType` STRING. To override this behavior (or avoid this warning), specify `is_ordered` during `ChoiceParameter` construction.\n",
            "  f'`{param_string}` is not specified for `ChoiceParameter` \"{self._name}\". '\n",
            "/usr/local/lib/python3.7/dist-packages/ax/core/parameter.py:468: UserWarning: `sort_values` is not specified for `ChoiceParameter` \"c2\". Defaulting to `False` for parameters of `ParameterType` STRING. To override this behavior (or avoid this warning), specify `sort_values` during `ChoiceParameter` construction.\n",
            "  f'`{param_string}` is not specified for `ChoiceParameter` \"{self._name}\". '\n",
            "[INFO 08-03 04:09:56] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[RangeParameter(name='x1', parameter_type=FLOAT, range=[0.0, 1.0]), RangeParameter(name='x2', parameter_type=FLOAT, range=[0.0, 1.0]), RangeParameter(name='x3', parameter_type=FLOAT, range=[0.0, 1.0]), RangeParameter(name='x4', parameter_type=FLOAT, range=[0.0, 1.0]), RangeParameter(name='x5', parameter_type=FLOAT, range=[0.0, 1.0]), ChoiceParameter(name='c1', parameter_type=STRING, values=['option_1', 'option_2', 'option_3'], is_ordered=False, sort_values=False), ChoiceParameter(name='c2', parameter_type=STRING, values=['option_1', 'option_2', 'option_3'], is_ordered=False, sort_values=False)], parameter_constraints=[]).\n",
            "[INFO 08-03 04:09:56] ax.service.ax_client: Generated new trial 0 with parameters {'x1': 0.549158, 'x2': 0.79813, 'x3': 0.113769, 'x4': 0.30397, 'x5': 0.049273, 'c1': 'option_1', 'c2': 'option_1'}.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "[INFO 08-03 04:09:56] ax.service.ax_client: Completed trial 0 with data: {'mae': (0.123, None), 'rmse': (0.234, None)}.\n",
            "[INFO 08-03 04:09:56] ax.service.ax_client: Generated new trial 1 with parameters {'x1': 0.972214, 'x2': 0.866834, 'x3': 0.962248, 'x4': 0.145818, 'x5': 0.406151, 'c1': 'option_1', 'c2': 'option_2'}.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "[INFO 08-03 04:09:56] ax.service.ax_client: Completed trial 1 with data: {'mae': (0.123, None), 'rmse': (0.234, None)}.\n",
            "[INFO 08-03 04:09:56] ax.modelbridge.transforms.standardize_y: Outcome mae is constant, within tolerance.\n",
            "[INFO 08-03 04:09:56] ax.modelbridge.transforms.standardize_y: Outcome rmse is constant, within tolerance.\n",
            "[INFO 08-03 04:09:58] ax.service.ax_client: Generated new trial 2 with parameters {'x1': 1.0, 'x2': 0.989955, 'x3': 0.994395, 'x4': 0.014503, 'x5': 0.957823, 'c1': 'option_1', 'c2': 'option_2'}.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "[INFO 08-03 04:09:58] ax.service.ax_client: Completed trial 2 with data: {'mae': (0.123, None), 'rmse': (0.234, None)}.\n",
            "[INFO 08-03 04:09:58] ax.modelbridge.transforms.standardize_y: Outcome mae is constant, within tolerance.\n",
            "[INFO 08-03 04:09:58] ax.modelbridge.transforms.standardize_y: Outcome rmse is constant, within tolerance.\n",
            "[INFO 08-03 04:09:58] ax.service.utils.best_point: Using inferred objective thresholds: [ObjectiveThreshold(mae <= 0.12300000999999999), ObjectiveThreshold(rmse <= 0.23400001)], as objective thresholds were not specified as part of the optimization configuration on the experiment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_parameters)\n",
        "print(pareto_optimal_parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr84t7pcvPDl",
        "outputId": "f30883f4-c633-4497-910b-938d1d832453"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "{0: ({'x1': 0.5491577982902527, 'x2': 0.7981299757957458, 'x3': 0.11376936733722687, 'x4': 0.30396953225135803, 'x5': 0.049272939562797546, 'c1': 'option_1', 'c2': 'option_1'}, ({'mae': 0.123, 'rmse': 0.234}, {'mae': {'mae': 0.06215899797521851, 'rmse': 0.0}, 'rmse': {'mae': 0.0, 'rmse': 0.06215899797521851}}))}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Graveyard"
      ],
      "metadata": {
        "id": "lFmpACE_8hSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        # test_df = test_inputs.to_frame(name=\"formula\")\n",
        "        # test_df[\"target\"] = 0.0\n",
        "\n",
        "# class RandomSearch(num_iterations=100, param_types: dict(x0=\"float\", x1=\"float\", x2=\"float\", x3=\"float\", x4=\"float\", c0=\"string\", c1=\"string\")):\n",
        "#   def __init__():\n",
        "#     pass\n",
        "#   def get_next_trial():\n",
        "\n",
        "\n",
        "# from ax import optimize\n",
        "# best_parameters, values, experiment, model = optimize(\n",
        "#     parameters=[\n",
        "#         {\n",
        "#             \"name\": \"x0\",\n",
        "#             \"type\": \"range\",\n",
        "#             \"bounds\": [-5.0, 10.0],\n",
        "#         },\n",
        "#         {\n",
        "#             \"name\": \"x1\",\n",
        "#             \"type\": \"range\",\n",
        "#             \"bounds\": [0.0, 10.0],\n",
        "#         },\n",
        "#         {\n",
        "#             \"name\": \"x2\",\n",
        "#             \"type\": \"range\",\n",
        "#             \"bounds\": [-5.0, 10.0],\n",
        "#         },\n",
        "#         {\n",
        "#             \"name\": \"x3\",\n",
        "#             \"type\": \"range\",\n",
        "#             \"bounds\": [0.0, 10.0],\n",
        "#         },\n",
        "#         {\n",
        "#             \"name\": \"x4\",\n",
        "#             \"type\": \"range\",\n",
        "#             \"bounds\": [0.0, 10.0],\n",
        "#         },\n",
        "#     ],\n",
        "#     evaluation_function=branin_evaluation_function,\n",
        "#     minimize=True,\n",
        "# )\n",
        "\n",
        "\n",
        "# from ax.utils.measurement.synthetic_functions import branin\n",
        "# def augmented_branin_evaluation_function(parameters):\n",
        "#     mean = branin(parameters[\"x1\"], parameters[\"x2\"])\n",
        "#     parameters[\"x3\"]  # unused float parameter\n",
        "#     parameters[\"x4\"]  # unused float parameter\n",
        "#     parameters[\"x5\"]  # unused float parameter\n",
        "#     parameters[\"c1\"]  # unused categorical parameter\n",
        "#     parameters[\"c2\"]  # unused categorical parameter\n",
        "#     # return std_dev is optional\n",
        "#     # std = 0.0\n",
        "#     # return (mean, std)\n",
        "#     return {\"objective_1\": mean, \"objective_2\": mean}\n",
        "\n",
        "# extra_objs = np.setdiff1d(objectives, SUPPORTED_OBJECTIVES)"
      ],
      "metadata": {
        "id": "b8n9_doD8h0P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}